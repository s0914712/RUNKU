#!/usr/bin/env python3
"""
Generate examples for vocabulary words using Apertis AI API
"""
import os
import json
import httpx
from pathlib import Path
from datetime import datetime

# API è¨­å®š
APERTIS_API_KEY = os.getenv('APERTIS_API_KEY')
APERTIS_MODEL = 'grok-4.1-fast:free'
APERTIS_BASE_URL = 'https://api.apertis.ai/v1'

# æª”æ¡ˆè·¯å¾‘
WORDS_FILE = Path('words')
OUTPUT_FILE = Path('data/vocabulary.json')


def parse_words_file():
    """è§£æ words æª”æ¡ˆï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""
    words = []
    
    if not WORDS_FILE.exists():
        print(f"âŒ File not found: {WORDS_FILE}")
        return words
    
    with open(WORDS_FILE, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue
            
            # æ”¯æ´æ ¼å¼: "ä¸­æ–‡-è‹±æ–‡" æˆ– "è‹±æ–‡-ä¸­æ–‡" æˆ–å–®ç´”å–®å­—
            if '-' in line:
                parts = line.split('-', 1)
                chinese = parts[0].strip()
                english = parts[1].strip()
                
                # åˆ¤æ–·å“ªé‚Šæ˜¯ä¸­æ–‡
                if any('\u4e00' <= c <= '\u9fff' for c in chinese):
                    words.append({'chinese': chinese, 'english': english})
                else:
                    words.append({'chinese': english, 'english': chinese})
            else:
                # åªæœ‰è‹±æ–‡çš„æƒ…æ³ï¼Œä¸­æ–‡ç•™ç©º
                words.append({'chinese': '', 'english': line})
    
    return words


def load_existing_data():
    """è¼‰å…¥å·²å­˜åœ¨çš„ vocabulary.json"""
    if OUTPUT_FILE.exists():
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {'words': [], 'last_updated': None}


def generate_examples(word_entry):
    """ä½¿ç”¨ Apertis API ç”Ÿæˆä¾‹å¥å’Œç”¨æ³•æç¤º"""
    chinese = word_entry['chinese']
    english = word_entry['english']
    
    prompt = f"""ç‚ºé€™å€‹è‹±æ–‡å–®å­—ç”Ÿæˆå­¸ç¿’ææ–™ï¼ˆè«‹ç”¨ç¹é«”ä¸­æ–‡å›ç­”ï¼‰ï¼š

å–®å­—: {english}
ä¸­æ–‡: {chinese if chinese else '(è«‹æä¾›ä¸­æ–‡ç¿»è­¯)'}

è«‹æä¾›ä»¥ä¸‹å…§å®¹ï¼Œä½¿ç”¨ JSON æ ¼å¼å›ç­”ï¼š
1. chinese_translation: å¦‚æœæ²’æœ‰ä¸­æ–‡ç¿»è­¯ï¼Œè«‹æä¾›
2. examples: 3å€‹å¯¦ç”¨çš„è‹±æ–‡ä¾‹å¥ï¼ˆå¾ç°¡å–®åˆ°è¤‡é›œï¼‰
3. usage_tips: ç°¡çŸ­çš„ç”¨æ³•èªªæ˜ï¼ˆ30å­—å…§ï¼‰
4. difficulty: é›£åº¦ç­‰ç´š 1-5 (1=åŸºç¤, 5=é€²éš)
5. category: è©æ€§ï¼ˆå¦‚ noun, verb, adjective ç­‰ï¼‰

JSONæ ¼å¼ç¯„ä¾‹ï¼š
{{
  "chinese_translation": "é–‹æ”¾çš„",
  "examples": [
    "The store is open.",
    "She has an open mind.",
    "They opened a new restaurant."
  ],
  "usage_tips": "å¸¸ç”¨æ–¼æè¿°ç‹€æ…‹æˆ–æ…‹åº¦",
  "difficulty": 2,
  "category": "adjective"
}}"""

    try:
        with httpx.Client(timeout=60.0) as client:
            response = client.post(
                f"{APERTIS_BASE_URL}/chat/completions",
                headers={
                    "Authorization": f"Bearer {APERTIS_API_KEY}",
                    "Content-Type": "application/json"
                },
                json={
                    "model": APERTIS_MODEL,
                    "messages": [
                        {"role": "user", "content": prompt}
                    ],
                    "max_tokens": 1024,
                    "temperature": 0.7
                }
            )
            response.raise_for_status()
            result_json = response.json()
            response_text = result_json["choices"][0]["message"]["content"]
            
            # æå– JSON
            start = response_text.find('{')
            end = response_text.rfind('}') + 1
            if start != -1 and end > start:
                json_str = response_text[start:end]
                return json.loads(json_str)
            
            return None
            
    except Exception as e:
        print(f"âŒ Error generating examples for '{english}': {e}")
        return None


def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸš€ Starting vocabulary generation...")
    
    # ç¢ºä¿ data ç›®éŒ„å­˜åœ¨
    OUTPUT_FILE.parent.mkdir(exist_ok=True)
    
    # è¼‰å…¥ç¾æœ‰è³‡æ–™
    data = load_existing_data()
    existing_words = {w['english']: w for w in data['words']}
    
    # è§£æ words æª”æ¡ˆ
    words = parse_words_file()
    print(f"ğŸ“š Found {len(words)} words in file")
    
    # è™•ç†æ¯å€‹å–®å­—
    updated_count = 0
    new_count = 0
    
    for word_entry in words:
        english = word_entry['english']
        
        # å¦‚æœå·²ç¶“æœ‰ä¾‹å¥ï¼Œè·³é
        if english in existing_words and 'examples' in existing_words[english]:
            print(f"â­ï¸  Skip '{english}' (already has examples)")
            continue
        
        print(f"ğŸ”„ Generating examples for '{english}'...")
        result = generate_examples(word_entry)
        
        if result:
            # æ›´æ–°æˆ–æ–°å¢
            if english in existing_words:
                existing_words[english].update({
                    'chinese': result.get('chinese_translation', word_entry['chinese']),
                    'examples': result['examples'],
                    'usage_tips': result['usage_tips'],
                    'difficulty': result['difficulty'],
                    'category': result['category'],
                    'updated_at': datetime.now().isoformat()
                })
                updated_count += 1
            else:
                existing_words[english] = {
                    'english': english,
                    'chinese': result.get('chinese_translation', word_entry['chinese']),
                    'examples': result['examples'],
                    'usage_tips': result['usage_tips'],
                    'difficulty': result['difficulty'],
                    'category': result['category'],
                    'created_at': datetime.now().isoformat()
                }
                new_count += 1
            
            print(f"âœ… Generated for '{english}'")
    
    # å„²å­˜çµæœ
    data['words'] = list(existing_words.values())
    data['last_updated'] = datetime.now().isoformat()
    data['total_words'] = len(data['words'])
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ¨ Complete!")
    print(f"  ğŸ“ New words: {new_count}")
    print(f"  ğŸ”„ Updated words: {updated_count}")
    print(f"  ğŸ“Š Total words: {len(data['words'])}")
    print(f"  ğŸ’¾ Saved to: {OUTPUT_FILE}")


if __name__ == '__main__':
    main()
